import numpy as np
import os
import re
from elephant.conversion import BinnedSpikeTrain
import neo
import quantities as pq

def get_data_nest(path, pattern="brunel-py-ex-*"):
    """
    read dat file with spikes inside
    :param path: path of files
    :param pattern: pattern to identify the files (one generated by MPI process)
    :return: spikes time
    """

    def _blockread(fname, skiprows=0, skiphead=3):
        a = []
        with open(fname, 'r') as f:
            while True:
                line = None
                for i in range(skiprows + skiphead):
                    line = f.readline()
                    if not line:
                        break
                if not line:
                    break
                for i in range(int(1e6)):
                    line = f.readline()
                    if not line:
                        break
                    a.append(line.split())
                yield a
        if a == []:
            raise Exception('stop file')

    re_pattern = re.compile(pattern)
    data = []
    for file in os.listdir(path):
        if re.match(re_pattern, file) is not None:
            for i in _blockread(path + file):
                for id, time in i:
                    data.append([int(id), float(time)])
    return np.array(data)

def get_data_neuron(path):
    data = np.load(path, allow_pickle=True)
    tmp = np.copy(data[1])
    data[1] = data[0]
    data[0] = tmp
    return data.swapaxes(0,1)


def get_hist(path, hist_binwidth=1, begin=50.0, end=1000.0, nest=True):
    if nest:
        spikes = get_data_nest(path)
    else:
        spikes = get_data_neuron(path)
    t_bins = np.arange(
        begin,end+hist_binwidth,
        float(hist_binwidth)
    )
    n, _ = np.histogram(spikes, bins=t_bins)
    return n


def get_spiketrains(path, nb_neurons, begin=50, end=1000, first_id=1,binwidth=1, nest=True):
    if nest:
        spikes = get_data_nest(path)
    else:
        spikes = get_data_neuron(path)
    max_spikes = np.max(np.bincount(np.array(spikes[:,0],dtype=int)))
    spiketrains=np.ones((nb_neurons, max_spikes))*-1
    for id_nest, times in spikes:
        id=int(id_nest-first_id)
        if begin < times:
           spiketrains[id-1, np.where(spiketrains[id-1,:] ==-1)[0][0]] = times
    neo_spiketrains =[]
    for spiketrain in spiketrains:
        neo_spiketrains.append(neo.SpikeTrain(spiketrain[np.where(spiketrain !=-1)], t_start=begin, t_stop=end, units='ms'))

    return neo_spiketrains, BinnedSpikeTrain(neo_spiketrains, binsize=binwidth * pq.ms)


# get_hist('/home/kusch/Documents/project/co_simulation/TVB-NEST-proof/result_sim/nest_only/nest/')
# get_spiketrains('/home/kusch/Documents/project/co_simulation/TVB-NEST-proof/result_sim/nest_only/nest/', nb_neurons=50)
